{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping List of 300 Jobs\n",
    "s1 = '&start='\n",
    "url_loop_str = ['']\n",
    "for i in np.arange(25,300,25):\n",
    "    url_loop_str.append(s1+str(i))\n",
    "\n",
    "soup = bs4.BeautifulSoup()\n",
    "\n",
    "for i in url_loop_str:\n",
    "\n",
    "    base_url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\"\n",
    "    keyword = \"Data%20Science\"\n",
    "    location = \"United%20States\"\n",
    "    refresh = \"true\"\n",
    "    \n",
    "    soup_list = []\n",
    "\n",
    "    url = f\"{base_url}?keywords={keyword}&location={location}&refresh={refresh}{i}\"\n",
    "    page = requests.get(url)\n",
    "\n",
    "    recepie = bs4.BeautifulSoup(page.text,\"html\")\n",
    "\n",
    "    soup.append(recepie) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(soup):\n",
    "\n",
    "    role = []\n",
    "    c_name = []\n",
    "    dt = []\n",
    "    loc = []\n",
    "    j_url = []\n",
    "    c_url = []\n",
    "    ind = ''\n",
    "    \n",
    "    n_applicants = []\n",
    "    salary_range = []\n",
    "\n",
    "    seniority_level = []\n",
    "    employement_type = []\n",
    "    job_function = []\n",
    "    industry = []\n",
    "\n",
    "    about_info = []\n",
    "\n",
    "    raw_list = soup.find_all('li')\n",
    "\n",
    "    for i in range(len(raw_list)):\n",
    "        \n",
    "        # Position --------------------------------------------\n",
    "        role.append(raw_list[i].h3.contents[0].strip())\n",
    "        \n",
    "        # Company Name\n",
    "        if raw_list[i].h4.a:\n",
    "            c_name.append(raw_list[i].h4.a.contents[0].strip())\n",
    "        else: \n",
    "            c_name.append(raw_list[i].h4.contents[0].strip())\n",
    "        \n",
    "        # Job Location ----------------------------------------\n",
    "        if raw_list[i].find(class_ = 'job-search-card__location').contents[0].strip():\n",
    "            loc.append(raw_list[i].find(class_ = 'job-search-card__location').contents[0].strip())\n",
    "        else: \n",
    "            loc.append('')\n",
    "        \n",
    "        # Job Posting Date ------------------------------------\n",
    "        if raw_list[i].find(class_ = 'job-search-card__listdate'):\n",
    "            dt.append(raw_list[i].find(class_ = 'job-search-card__listdate').contents[0].strip())\n",
    "        else: \n",
    "            dt.append(raw_list[i].find(class_ = 'job-search-card__listdate--new').contents[0].strip())\n",
    "\n",
    "        # Job Post URL ----------------------------------------\n",
    "        if raw_list[i].find_all('a', href=True)[0]:\n",
    "            j_url.append(raw_list[i].find_all('a', href=True)[0]['href'])\n",
    "        else: \n",
    "            j_url.append('') \n",
    "        \n",
    "        if raw_list[i].find_all('a', href=True)[0]:\n",
    "            n_applicants_var, salary_range_var, seniority_level_var, employement_type_var, job_function_var, industry_var, about_info_var = extract_job_attr(raw_list[i].find_all('a', href=True)[0]['href'])\n",
    "        else:\n",
    "            n_applicants_var, salary_range_var, seniority_level_var, employement_type_var, job_function_var, industry_var, about_info_var = '', '', '', '', '', '', ''\n",
    "        \n",
    "        n_applicants.append(n_applicants_var)\n",
    "        salary_range.append(salary_range_var)\n",
    "\n",
    "        seniority_level.append(seniority_level_var)\n",
    "        employement_type.append(employement_type_var)\n",
    "        job_function.append(job_function_var)\n",
    "        industry.append(industry_var)\n",
    "\n",
    "        about_info.append(about_info_var)\n",
    "\n",
    "        # Company URL ----------------------------------------\n",
    "        if len(raw_list[i].find_all('a', href=True)) == 2:\n",
    "            c_url.append(raw_list[i].find_all('a', href=True)[1]['href'])\n",
    "        else: \n",
    "            c_url.append('')\n",
    "\n",
    "    df = pd.DataFrame(list(zip(role, c_name, loc, dt, j_url, c_url, \n",
    "                               n_applicants, salary_range, \n",
    "                               seniority_level, employement_type, job_function, industry, \n",
    "                               about_info)),\n",
    "                    columns =['JOB_ROLE', 'COMPANY', 'LOCATION', 'POST_DATE', 'JOB_URL', 'COMPANY_URL',\n",
    "                              'N_APPLICANTS', 'SALARY_RANGE', \n",
    "                              'SENIORITY_LEVEL', 'EMPLOYEMENT_TYPE', 'JOB_FUNCTION', 'INDUSTRY',\n",
    "                              'ABOUT'])\n",
    "\n",
    "    df = df[~df['JOB_ROLE'].str.upper().str.contains('INTERN')]\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Job Attributes\n",
    "def extract_job_attr(url):\n",
    "    if url == '':\n",
    "        return '', '', '', '', '', '', ''\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    n_applicants = ''\n",
    "    salary_range = ''\n",
    "\n",
    "    seniority_level = ''\n",
    "    employement_type = ''\n",
    "    job_function = ''\n",
    "    industry = ''\n",
    "    about_info = ''\n",
    "\n",
    "    # No. Applicants ----------------------------------------\n",
    "    if soup.find(class_ = 'num-applicants__caption'):\n",
    "        n_applicants = soup.find(class_ = 'num-applicants__caption').contents[0].strip()\n",
    "    else: \n",
    "        n_applicants = ''\n",
    "        \n",
    "    # Compensation ----------------------------------------\n",
    "    if soup.find(class_ = 'salary compensation__salary'):\n",
    "        salary_range = soup.find(class_ = 'salary compensation__salary').contents[0].strip()\n",
    "    else: \n",
    "        salary_range = ''\n",
    "\n",
    "    # Job Attributes --------------------------------------\n",
    "    job_attr = soup.find_all(class_ = 'description__job-criteria-text description__job-criteria-text--criteria')\n",
    "    if job_attr:\n",
    "        seniority_level = job_attr[0].contents[0].strip() if job_attr[0].contents else ''\n",
    "        employement_type = job_attr[1].contents[0].strip() if job_attr[1].contents else ''\n",
    "        job_function = job_attr[2].contents[0].strip() if job_attr[2].contents else ''\n",
    "        industry = job_attr[3].contents[0].strip() if job_attr[3].contents else ''\n",
    "    else:\n",
    "        seniority_level = ''\n",
    "        employement_type = ''\n",
    "        job_function = ''\n",
    "        industry = ''\n",
    "    \n",
    "    # About ----------------------------------------------\n",
    "    if soup.find(class_ = 'show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden'):\n",
    "        for i in soup.find(class_ = 'show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden').contents:\n",
    "            about_info += str(i)\n",
    "    \n",
    "    return n_applicants, salary_range, seniority_level, employement_type, job_function, industry, about_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_ROLE</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>POST_DATE</th>\n",
       "      <th>JOB_URL</th>\n",
       "      <th>COMPANY_URL</th>\n",
       "      <th>N_APPLICANTS</th>\n",
       "      <th>SALARY_RANGE</th>\n",
       "      <th>SENIORITY_LEVEL</th>\n",
       "      <th>EMPLOYEMENT_TYPE</th>\n",
       "      <th>JOB_FUNCTION</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>ABOUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist, GBG Data Science</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>https://www.linkedin.com/company/meta?trk=publ...</td>\n",
       "      <td>98 applicants</td>\n",
       "      <td>$134,000.00/yr - $194,000.00/yr</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>\\n        The massive scale and heavy engageme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist, GBG Data Science</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>https://www.linkedin.com/company/meta?trk=publ...</td>\n",
       "      <td>94 applicants</td>\n",
       "      <td>$134,000.00/yr - $194,000.00/yr</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Technology, Information and Internet</td>\n",
       "      <td>\\n        The massive scale and heavy engageme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist, Marketing</td>\n",
       "      <td>Asana</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>https://www.linkedin.com/company/asana?trk=pub...</td>\n",
       "      <td>Over 200 applicants</td>\n",
       "      <td>$171,000.00/yr - $258,000.00/yr</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>\\n&lt;p&gt;Asana's Data Science team helps us fulfil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ML Engineer (Entry Level)</td>\n",
       "      <td>Grindr</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/ml-engineer...</td>\n",
       "      <td>https://www.linkedin.com/company/grindr?trk=pu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Intel Corporation</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>https://www.linkedin.com/company/intel-corpora...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            JOB_ROLE            COMPANY           LOCATION  \\\n",
       "11  Data Scientist, GBG Data Science               Meta       New York, NY   \n",
       "12  Data Scientist, GBG Data Science               Meta       New York, NY   \n",
       "14         Data Scientist, Marketing              Asana  San Francisco, CA   \n",
       "15         ML Engineer (Entry Level)             Grindr  San Francisco, CA   \n",
       "16                      Data Analyst  Intel Corporation        Phoenix, AZ   \n",
       "\n",
       "      POST_DATE                                            JOB_URL  \\\n",
       "11   1 week ago  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "12   1 week ago  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "14  2 weeks ago  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "15   1 week ago  https://www.linkedin.com/jobs/view/ml-engineer...   \n",
       "16   1 week ago  https://www.linkedin.com/jobs/view/data-analys...   \n",
       "\n",
       "                                          COMPANY_URL         N_APPLICANTS  \\\n",
       "11  https://www.linkedin.com/company/meta?trk=publ...        98 applicants   \n",
       "12  https://www.linkedin.com/company/meta?trk=publ...        94 applicants   \n",
       "14  https://www.linkedin.com/company/asana?trk=pub...  Over 200 applicants   \n",
       "15  https://www.linkedin.com/company/grindr?trk=pu...                        \n",
       "16  https://www.linkedin.com/company/intel-corpora...                        \n",
       "\n",
       "                       SALARY_RANGE   SENIORITY_LEVEL EMPLOYEMENT_TYPE  \\\n",
       "11  $134,000.00/yr - $194,000.00/yr    Not Applicable        Full-time   \n",
       "12  $134,000.00/yr - $194,000.00/yr    Not Applicable        Full-time   \n",
       "14  $171,000.00/yr - $258,000.00/yr  Mid-Senior level        Full-time   \n",
       "15                                                                       \n",
       "16                                                                       \n",
       "\n",
       "                              JOB_FUNCTION  \\\n",
       "11  Engineering and Information Technology   \n",
       "12  Engineering and Information Technology   \n",
       "14                             Engineering   \n",
       "15                                           \n",
       "16                                           \n",
       "\n",
       "                                INDUSTRY  \\\n",
       "11  Technology, Information and Internet   \n",
       "12  Technology, Information and Internet   \n",
       "14                  Software Development   \n",
       "15                                         \n",
       "16                                         \n",
       "\n",
       "                                                ABOUT  \n",
       "11  \\n        The massive scale and heavy engageme...  \n",
       "12  \\n        The massive scale and heavy engageme...  \n",
       "14  \\n<p>Asana's Data Science team helps us fulfil...  \n",
       "15                                                     \n",
       "16                                                     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get(soup)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aakashrathod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/mn/89jgthfx1f7b2mlbmf36w11c0000gn/T/ipykernel_61315/466306341.py:7: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for i,j in data.ABOUT.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>20699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experience</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learning</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>existed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>crave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>post-event</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>segmented</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>deadline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6416 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1\n",
       "0                 20699\n",
       "1           data   1640\n",
       "2     experience    645\n",
       "3           work    419\n",
       "4       learning    356\n",
       "...          ...    ...\n",
       "6411     existed      1\n",
       "6412       crave      1\n",
       "6413  post-event      1\n",
       "6414   segmented      1\n",
       "6415    deadline      1\n",
       "\n",
       "[6416 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_freq(data):\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    s1 = ''\n",
    "    rm_list = ['*','%','[',']','#','%','•','©','®','+','</ol>','<ol>','<span>','</span>','<u>','</u>']\n",
    "    for i,j in data.ABOUT.iteritems():\n",
    "        s1 += j\n",
    "\n",
    "    s1 = s1.replace('<br/>',' ').replace('</strong>',' ').replace('<strong>', ' ').replace('</li>', ' ').replace('<li>', ' ').replace('<ul>', ' ').replace('</ul>', ' ').replace('<em>', ' ').replace('</em>', ' ').replace('</p>', ' ').replace('<p>', ' ').replace(',', ' ').replace('.',' ').replace('(',' ').replace(')',' ').replace(\"’\",' ').lower()\n",
    "\n",
    "    for i in rm_list:\n",
    "        s1 = s1.replace(i, ' ')\n",
    "\n",
    "    s2 = s1.split(' ') \n",
    "\n",
    "    s3 = [i for i in s2 if i not in stopwords.words('english')]\n",
    "\n",
    "    res = dict(Counter(s3))\n",
    "\n",
    "    res2 = {}\n",
    "    for w in sorted(res, key=res.get, reverse=True):\n",
    "        res2[w] = res[w]\n",
    "    return pd.DataFrame(res2.items())\n",
    "\n",
    "frequency_analysis = get_freq(data)\n",
    "frequency_analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('LinkedIn Job DS.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "data.to_excel(writer, sheet_name= 'Jobs', index = False)\n",
    "frequency_analysis.to_excel(writer, sheet_name= 'Frequency', index = False)\n",
    "\n",
    "writer.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4d68a23e7b17350b5bd8ece07a2edd2e738708fe9640219d0e8e39fd293cd5a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
